---
layout:     page
title:
permalink:  /
---

<div class="row">
    <div class="col-sm-6 col-xs-12">
        <img src="/img/cover2.jpg">
    </div>
    <div class="col-sm-6 col-xs-12" style="margin-bottom: 0;">
        AI Resident<br>
        Meta AI<br>
        prajj at meta dot com
    </div>
</div>
<hr>

<a name="/news"></a>

# News
* [May 23] New [preprint](https://arxiv.org/abs/2305.14550) titled "Sequence Modeling is a robust contender for Offline RL" is out.
* [Mar 23] New [preprint](https://arxiv.org/abs/2303.06245) on multi-task dialogue model for faster training and inference.
* [Oct 22] Paper accepted at EMNLP 2022. Camera ready draft and code coming soon.
* [Apr 22] I'll be joining Meta AI (FAIR) as an AI Resident at Menlo Park.
* [Oct 21]  Survey paper has been accepted at AAAI 2022.
* [Sept 21] Paper accepted at EMNLP Insights from Negative Results Workshop 2021.
* [Oct 20] Declared winner of Pytorch Global Hackathon 2020 in the responsible AI category
* [Aug 20] I'll be joining UT Dallas as an MSCS student
* [June 20] Will serve as a volunteer for [ACL](https://acl2020.org/), Seattle 2020
* [June 20] Secured 18th spot at CVPR 2020 [VQA challenge](https://visualqa.org/roe)
* [June 20] Will serve as a volunteer for [ICML](https://icml.cc/Conferences/2020), Vienna 2020
* [May 20] My paper on Adaptive Transformers is available on [arxiv](https://arxiv.org/abs/2005.07486)
* [Apr 20] 1 Paper accepted at ACL SRW 2020
* [Apr 20] I'll be a volunteer for ICLR 2020
* [Feb 20] I joined Siemens again as a research intern to work on Predictive Maintenance.
* [Nov 19] Iâ€™ll be doing the Poster presentation at ICCV 2019, Seoul.
* [August 19] 1 paper accepted at ICCV workshop 2019
* [Jan 19] I joined Siemens as a research intern (Autonomous Navigation group)

<div id="read-more-button">
    <a nohref>Read more</a>
</div>

<hr>

<a name="/bio"></a>

# Bio

I am an AI Resident at [Meta AI](https://ai.facebook.com) in the [Generative AI](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/) team working on LLM Research with [Sharan Narang](https://scholar.google.com/citations?user=CWOixywAAAAJ&hl=en). Specifically I am working on building rigorous evaluation systems for LLMs, improving performance on long context tasks and multilingual capabilities of LLaMA family of models. Previously I was in the Cognitive AI team working with different learning paradigms within Offline RL with [Rohan Chitnis](https://rohanchitnis.com) and [Amy Zhang](https://amyzhang.github.io), and before that I was in [Conversational AI Research](https://ai.facebook.com/research/conversational-ai/) working with [Chinnadhurai Sankar](https://chinnadhurai.github.io) on multi-task dialogue models.

I was a CS graduate student at the University of Texas Dallas where I worked on commonsense reasoning under the supervision of [Prof. Vincent Ng](http://www.hlt.utdallas.edu/~vince/). My [thesis](https://libtreasures.utdallas.edu/handle/10735.1/9511) is about improving commonsense reasoning through adversarial learning.

<a name="/publications"></a>

# Publications

<a name="/seq-model-offline-rl"></a>
<h2 class="pubt">Sequence Modeling is a Robust Contender for Offline Reinforcement Learning</h2>
<p class="pubd">
    <span class="authors">Prajjwal Bhargava, Rohan Chitnis, Alborz Geramifard, Shagun Sodhani, Amy Zhang </span><br>
<!--     <span class="conf">arXiv 2023</span> -->
    <span class="conf"></span>
    <span class="links">
        <a target="_blank" href="https://arxiv.org/abs/2305.14550">arXiv</a>
<!--         <a target="_blank" href="https://github.com/prajjwal1/prajjwal1.github.io/raw/master/img/seq_model_offline_rl/seq_model_offline_rl.png">Poster</a> -->
        <a target="_blank" href="https://github.com/prajjwal1/rl_paradigms">Code</a>
<a target="_blank" href="https://raw.githubusercontent.com/prajjwal1/prajjwal1.github.io/master/bibtex/seq_model_offline_rl.bib">Bibtex</a>
    </span>
</p>
<img src="/img/seq_model_offline_rl/seq_model_offline_rl.png">
<hr>

<a name="/autodial"></a>
<h2 class="pubt">AUTODIAL: Efficient Asynchronous Task-Oriented Dialogue Model</h2>
<p class="pubd">
    <span class="authors">Prajjwal Bhargava, Pooyan Amini, Shahin Shayandeh, Chinnadhurai Sankar </span><br>
<!--     <span class="conf">EMNLP 2022</span> -->
    <span class="conf"></span>
    <span class="links">
        <a target="_blank" href="https://arxiv.org/abs/2303.06245">arXiv</a>
<!--         <a target="_blank" href="https://github.com/prajjwal1/prajjwal1.github.io/raw/master/img/emnlp_22/af.png">Poster</a> -->
        <a target="_blank" href="https://github.com/prajjwal1/autodial">Code</a>
<a target="_blank" href="https://raw.githubusercontent.com/prajjwal1/prajjwal1.github.io/master/bibtex/autodial.bib">Bibtex</a>
    </span>
</p>
<img src="/img/autodial/autodial.png">
<hr>




<a name="/discosense"></a>
<h2 class="pubt">DiscoSense: Commonsense Reasoning with Discourse Relations</h2>
<p class="pubd">
    <span class="authors">Prajjwal Bhargava and Vincent Ng</span><br>
    <span class="conf">EMNLP 2022</span>
    <span class="conf"></span>
    <span class="links">
        <a target="_blank" href="https://arxiv.org/abs/2210.12478">arXiv</a>
<!--         <a target="_blank" href="https://github.com/prajjwal1/prajjwal1.github.io/raw/master/img/emnlp_22/af.png">Poster</a> -->
        <a target="_blank" href="https://github.com/prajjwal1/discosense">Code</a>
<a target="_blank" href="https://raw.githubusercontent.com/prajjwal1/prajjwal1.github.io/master/bibtex/discosense.bib">Bibtex</a>
    </span>
</p>
<img src="/img/emnlp_22/af.png">
<hr>

<a name="/commonsense-survey"></a>
<h2 class="pubt">Commonsense Knowledge Reasoning and Generation with Pre-trained Language Models: A Survey</h2>
<p class="pubd">
    <span class="authors">Prajjwal Bhargava and Vincent Ng</span><br>
    <span class="conf">AAAI 2022</span>
    <span class="conf"></span>
    <span class="links">
        <a target="_blank" href="https://arxiv.org/abs/2201.12438">Paper</a>
        <a target="_blank" href="https://github.com/prajjwal1/prajjwal1.github.io/raw/master/research/aaai-22/survey_poster.pdf">Poster</a>
        <a target="_blank" href="https://raw.githubusercontent.com/prajjwal1/prajjwal1.github.io/master/bibtex/commonsense_survey_aaai_22.bib">Bibtex</a>
    </span>
</p>
<img src="/img/survey/probe.png">
<hr>

<a name="/generalization-nli"></a>
<h2 class="pubt">Generalization in NLI: Ways to [Not] Go Beyond Simple Heuristics</h2>
<p class="pubd">
    <span class="authors">Prajjwal Bhargava, Aleksander Drozd, Anna Rogers</span><br>
    <span class="conf">EMNLP Workshop on Insights from Negative Results 2022</span>
    <span class="links">
        <a target="_blank" href="https://arxiv.org/abs/2110.01518">Paper</a>
        <a target="_blank" href="https://github.com/prajjwal1/generalize_lm_nli">Code (Huggingface)</a>
        <a target="_blank" href="https://github.com/vecto-ai/langmo">Code (Pytorch Lightning)</a>
        <a target="_blank" href="https://raw.githubusercontent.com/prajjwal1/prajjwal1.github.io/master/bibtex/generalize_lm_nli.bib">Bibtex</a>
        <a target="_blank" href="https://aclanthology.org/2021.insights-1.18.mp4">Presentation video</a>
        <a target="_blank" href="https://github.com/prajjwal1/prajjwal1.github.io/raw/master/research/emnlp-21/NLI_Generalization_EMNLP_Poster.pdf">Poster</a>
        <a target="_blank" href="https://github.com/prajjwal1/prajjwal1.github.io/raw/master/research/emnlp-21/chinese_room_presentation.pdf">Slides</a>

    </span>
</p>
<img src="/img/generalization_nli/MNLI_roberta-large.png">
<hr>

<a name="/adaptive"></a>
<h2 class="pubt">Adaptive Transformers for Learning Multimodal Representations</h2>
<p class="pubd">
    <span class="authors">Prajjwal Bhargava</span><br>
    <span class="conf">ACL SRW 2022</span>
    <span class="links">
        <a target="_blank" href="https://arxiv.org/abs/2005.07486">Paper</a>
        <a target="_blank" href="https://github.com/prajjwal1/adaptive_transformer">Code</a>
        <a target="_blank" href="https://raw.githubusercontent.com/prajjwal1/prajjwal1.github.io/master/bibtex/adaptive_transformer.bib">Bibtex</a>
        <a target="_blank" href="http://slideslive.com/38928637">Presentation Video</a>
    </span>
</p>
<img src="/img/adaptive/alpha.png">
<hr>

<a name="/detection"></a>
<h2 class="pubt">On Generalization of Detection Models for Unconstrained Environments</h2>
<p class="pubd">
    <span class="authors">Prajjwal Bhargava</span><br>
    <span class="conf">ICCV AutoNUE Workshop 2022</span>
    <span class="links">
        <a target="_blank" href="https://arxiv.org/abs/1909.13080">Paper</a>
        <a target="_blank" href="https://github.com/prajjwal1/autonomous-object-detection">Code</a>
        <a target="_blank" href="https://raw.githubusercontent.com/prajjwal1/prajjwal1.github.io/master/bibtex/gen_detection_models_iccvw19.bib">Bibtex</a>
        <a target="_blank" href="https://docs.google.com/presentation/d/1q6alY-5pRsJ2ys_402dhEOG0pVKk1VElDbegcXFFzoA/edit?usp=drivesdk">Poster</a>
    </span>
</p>
<img src="/img/detection/pipeline.png">
<hr>

<a name="/incremental"></a>
<h2 class="pubt">Incremental Learning in Person Re-Identification</h2>
<p class="pubd">
    <span class="authors">Prajjwal Bhargava</span><br>
    <span class="conf">arXiv preprint</span>
    <span class="links">
        <a target="_blank" href="https://arxiv.org/abs/1909.13080">Paper</a>
        <a target="_blank" href="https://github.com/prajjwal1/autonomous-object-detection">Code</a>
        <a target="_blank" href="https://raw.githubusercontent.com/prajjwal1/prajjwal1.github.io/master/bibtex/gen_detection_models_iccvw19.bib">Bibtex</a>
        <a target="_blank" href="https://docs.google.com/presentation/d/1q6alY-5pRsJ2ys_402dhEOG0pVKk1VElDbegcXFFzoA/edit?usp=drivesdk">Poster</a>
    </span>
</p>
<img src="/img/incremental/our_arch.png">
<hr>

<a name="/projects"></a>

# Side projects

<div class="row">
    <div class="col-sm-12">
        <h2 class="talkt" style="font-weight:300;"><a target="_blank" href="http://github.com/prajjwal1/fluence">fluence</a></h2>
        <p class="talkd">
            Winner of Pytorch Global Hackathon 2020. A Pytorch deep learning library focussed on
            providing support for compute efficient and debiasing algorithms in transformer based
            model for NLP research. Contains implementation of Adaptive Attention, Sparsity, Layerdrop,
            Debiasing, Pruning utilities etc.
            <a target="_blank" href="http://github.com/prajjwal1/fluence"><img style="margin-top: 10px;" src="/img/projects/fluence.png"></a>
        </p>
    </div>
</div>


<div class="row">
    <div class="col-sm-12">
        <h2 class="talkt" style="font-weight:300;"><a target="_blank" href="/open-source">Open source contributions</a></h2>
        <p class="talkd">
                        Contributions to Pytorch Ecosystem
            <a target="_blank" href="/open-source"><img class="project-img" src="/img/projects/hf_pytorch.png"></a>
        </p>
    </div>
</div>


<div class="row">
    <div class="col-sm-12">
        <h2 class="talkt" style="font-weight:300;"><a target="_blank" href="https://github.com/prajjwal1/autonomous-object-detection">Autonomous Object Detection</a></h2>
        <p class="talkd">
            This project focussed on 2D object detection with Pytorch.
            User can leverage models provided from `torchvision` and use datasets provided in this project (`idd`, `cityscapes`, `bdd`)
            for training and evaluation of models. Additionally, support for incremental learning was added.
            <a target="_blank" href="https://github.com/prajjwal1/autonomous-object-detection"><img src="/img/projects/baseline_preds.png"></a>
        </p>
    </div>
</div>

<script src="/js/jquery.min.js"></script>
<script type="text/javascript">
    $('ul:gt(0) li:gt(12)').hide();
    $('#read-more-button > a').click(function() {
        $('ul:gt(0) li:gt(12)').show();
        $('#read-more-button').hide();
    });
</script>

---
