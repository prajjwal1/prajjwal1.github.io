---
layout:     page
title:
permalink:  /
---

<div class="row">
    <div class="col-sm-6 col-xs-12">
        <img src="/img/cover2.jpg">
    </div>
    <div class="col-sm-6 col-xs-12" style="margin-bottom: 0;">
        AI Resident<br>
        Facebook AI Research<br>
        prajj at fb dot com
    </div>
</div>
<hr>

<a name="/news"></a>

# News
* [Mar 23] New [preprint](https://arxiv.org/abs/2303.06245) on multi-task dialogue model for faster training and inference.
* [Oct 22] Paper accepted at EMNLP 2022. Camera ready draft and code coming soon.
* [Apr 22] I'll be joining Meta AI (FAIR) as an AI Resident at Menlo Park.
* [Oct 21]  Survey paper has been accepted at AAAI 2022.
* [Sept 21] Paper accepted at EMNLP Insights from Negative Results Workshop 2021.
* [Oct 20] Declared winner of Pytorch Global Hackathon 2020 in the responsible AI category
* [Aug 20] I'll be joining UT Dallas as an MSCS student
* [June 20] Will serve as a volunteer for [ACL](https://acl2020.org/), Seattle 2020
* [June 20] Secured 18th spot at CVPR 2020 [VQA challenge](https://visualqa.org/roe)
* [June 20] Will serve as a volunteer for [ICML](https://icml.cc/Conferences/2020), Vienna 2020
* [May 20] My paper on Adaptive Transformers is available on [arxiv](https://arxiv.org/abs/2005.07486)
* [Apr 20] 1 Paper accepted at ACL SRW 2020
* [Apr 20] I'll be a volunteer for ICLR 2020
* [Feb 20] I joined Siemens again as a research intern to work on Predictive Maintenance.
* [Nov 19] Iâ€™ll be doing the Poster presentation at ICCV 2019, Seoul.
* [August 19] 1 paper accepted at ICCV workshop 2019
* [Jan 19] I joined Siemens as a research intern (Autonomous Navigation group)

<div id="read-more-button">
    <a nohref>Read more</a>
</div>

<hr>

<a name="/bio"></a>

# Bio

I am an AI Resident at [Meta AI Research](https://ai.facebook.com) (Reality Labs) in the [Cognitive AI team](https://ai.facebook.com/research/conversational-ai/) working with [Chinnadhurai Sankar](https://chinnadhurai.github.io), [Rohan Chitnis](https://rohanchitnis.com), [Amy Zhang](https://amyzhang.github.io).

Previously, I was a CS graduate student at the University of Texas Dallas where I worked on commonsense reasoning under
[Prof. Vincent Ng](http://www.hlt.utdallas.edu/~vince/). My thesis is about improving commonsense reasoning through adversarial
learning (coming soon). My research interests lie in the general area of deep learning and representation learning, especially at the intersection
of computer vision and language.

**Offline Reinforcement Learning**
This is what I'm currently working on. I am specifically working with Decision Transformer to understand how effective they are for sequential decision making.

**Vision**
I have previously worked on numerous domains in computer vision during my internships which includes
[Person Re-Identification](https://prajjwal1.github.io/publications/IncrementalPersonReid),
[Depth Perception and 3D Object Detection](https://www.youtube.com/watch?v=vlDTgj3Kut8). Out of my interests,
I've worked extensively on visual recognition based tasks and
[generalization of detection models](https://prajjwal1.github.io/publications/GenDetectionIccvw19).
I've also written numerous [blog posts](https://prajjwal1.github.io/blog/) about it.

**Language**
To explore further interests, I've made a transition to NLP especially language understanding and how we can form
generalized representations which can be harnessed for subsequent downstream tasks. I care about the accessibility
and impact marked by my research. Specifically, I looked at
[Adaptive methods](https://prajjwal1.github.io/publications/adaptive_tfmr_acl_srw_2020) and how can they be used to
create efficient Multi-modal transformer-based architectures. Recently I won
[Pytorch Global Summer Hackathon](https://pytorch.org/blog/announcing-the-winners-of-the-2020-global-pytorch-summer-hackathon/)
for my project [Fluence](https://github.com/prajjwal1/fluence). It focuses on addressing the task of language
understanding responsibly (fairness and computational efficiency).

My recent projects have looked more closely at reasoning. [Generalization in NLI ](https://arxiv.org/abs/2110.01518) project looked at how out-of-domain generalization in
pre-trained Language Models can be improved from biased data (MNLI -> HANS). My graduate research looked specifically
at commonsense reasoning within pre-trained Langauge Models. The [AAAI survey](https://arxiv.org/abs/2201.12438) provides
a comprehensive look at the strengths and weaknesses of state-of-the-art pre-trained models for commonsense reasoning and
generation. In the [EMNLP 2022]() paper, I propose a new commonsense reasoning task which puts emphasis on reasoning over discourse relations. We show how
learning representations from Discosense can help improve capabilities of langauge models.


I created a [Youtube channel](https://youtube.com/c/aijournal) to disseminate technical content from research papers.
After graduate school, my interest has changed about creating content as a result of which this project is
unmaintained right now.

<a name="/publications"></a>

# Publications

<a name="/autodial"></a>
<h2 class="pubt">DiscoSense: Commonsense Reasoning with Discourse Relations</h2>
<p class="pubd">
    <span class="authors">Prajjwal Bhargava, Pooyan Amini, Shahin Shayandeh, Chinnadhurai Sankar </span><br>
<!--     <span class="conf">EMNLP 2022</span> -->
    <span class="conf"></span>
    <span class="links">
        <a target="_blank" href="https://arxiv.org/abs/2303.06245">arXiv</a>
<!--         <a target="_blank" href="https://github.com/prajjwal1/prajjwal1.github.io/raw/master/img/emnlp_22/af.png">Poster</a> -->
        <a target="_blank" href="https://github.com/prajjwal1/autodial">Code</a>
<a target="_blank" href="https://raw.githubusercontent.com/prajjwal1/prajjwal1.github.io/master/bibtex/autodial.bib">Bibtex</a>
    </span>
</p> 
<img src="/img/emnlp_22/autodial.png">
<hr>




<a name="/discosense"></a>
<h2 class="pubt">DiscoSense: Commonsense Reasoning with Discourse Relations</h2>
<p class="pubd">
    <span class="authors">Prajjwal Bhargava and Vincent Ng</span><br>
    <span class="conf">EMNLP 2022</span>
    <span class="conf"></span>
    <span class="links">
        <a target="_blank" href="https://arxiv.org/pdf/2210.12478.pdf">arXiv</a>
<!--         <a target="_blank" href="https://github.com/prajjwal1/prajjwal1.github.io/raw/master/img/emnlp_22/af.png">Poster</a> -->
        <a target="_blank" href="https://github.com/prajjwal1/discosense">Code</a>
<a target="_blank" href="https://raw.githubusercontent.com/prajjwal1/prajjwal1.github.io/master/bibtex/discosense.bib">Bibtex</a>
    </span>
</p> 
<img src="/img/emnlp_22/af.png">
<hr>

<a name="/commonsense-survey"></a>
<h2 class="pubt">Commonsense Knowledge Reasoning and Generation with Pre-trained Language Models: A Survey</h2>
<p class="pubd">
    <span class="authors">Prajjwal Bhargava and Vincent Ng</span><br>
    <span class="conf">AAAI 2022</span>
    <span class="conf"></span>
    <span class="links">
        <a target="_blank" href="https://arxiv.org/abs/2201.12438">Paper</a>
        <a target="_blank" href="https://github.com/prajjwal1/prajjwal1.github.io/raw/master/research/aaai-22/survey_poster.pdf">Poster</a>
        <a target="_blank" href="https://raw.githubusercontent.com/prajjwal1/prajjwal1.github.io/master/bibtex/commonsense_survey_aaai_22.bib">Bibtex</a>
    </span>
</p>
<img src="/img/survey/probe.png">
<hr>

<a name="/generalization-nli"></a>
<h2 class="pubt">Generalization in NLI: Ways to [Not] Go Beyond Simple Heuristics</h2>
<p class="pubd">
    <span class="authors">Prajjwal Bhargava, Aleksander Drozd, Anna Rogers</span><br>
    <span class="conf">EMNLP Workshop on Insights from Negative Results 2022</span>
    <span class="links">
        <a target="_blank" href="https://arxiv.org/abs/2110.01518">Paper</a>
        <a target="_blank" href="https://github.com/prajjwal1/generalize_lm_nli">Code (Huggingface)</a>
        <a target="_blank" href="https://github.com/vecto-ai/langmo">Code (Pytorch Lightning)</a>
        <a target="_blank" href="https://raw.githubusercontent.com/prajjwal1/prajjwal1.github.io/master/bibtex/generalize_lm_nli.bib">Bibtex</a>
        <a target="_blank" href="https://www.youtube.com/watch?v=ByQu3J6Ji7E">Presentation video</a>
        <a target="_blank" href="https://github.com/prajjwal1/prajjwal1.github.io/raw/master/research/emnlp-21/NLI_Generalization_EMNLP_Poster.pdf">Poster</a>
        <a target="_blank" href="https://github.com/prajjwal1/prajjwal1.github.io/raw/master/research/emnlp-21/chinese_room_presentation.pdf">Slides</a>

    </span>
</p>
<img src="/img/generalization_nli/MNLI_roberta-large.png">
<hr>

<a name="/adaptive"></a>
<h2 class="pubt">Adaptive Transformers for Learning Multimodal Representations</h2>
<p class="pubd">
    <span class="authors">Prajjwal Bhargava</span><br>
    <span class="conf">ACL SRW 2022</span>
    <span class="links">
        <a target="_blank" href="https://arxiv.org/abs/2005.07486">Paper</a>
        <a target="_blank" href="https://github.com/prajjwal1/adaptive_transformer">Code</a>
        <a target="_blank" href="https://raw.githubusercontent.com/prajjwal1/prajjwal1.github.io/master/bibtex/adaptive_transformer.bib">Bibtex</a>
        <a target="_blank" href="http://slideslive.com/38928637">Presentation Video</a>
    </span>
</p>
<img src="/img/adaptive/alpha.png">
<hr>

<a name="/detection"></a>
<h2 class="pubt">On Generalization of Detection Models for Unconstrained Environments</h2>
<p class="pubd">
    <span class="authors">Prajjwal Bhargava</span><br>
    <span class="conf">ICCV AutoNUE Workshop 2022</span>
    <span class="links">
        <a target="_blank" href="https://arxiv.org/abs/1909.13080">Paper</a>
        <a target="_blank" href="https://github.com/prajjwal1/autonomous-object-detection">Code</a>
        <a target="_blank" href="https://raw.githubusercontent.com/prajjwal1/prajjwal1.github.io/master/bibtex/gen_detection_models_iccvw19.bib">Bibtex</a>
        <a target="_blank" href="https://docs.google.com/presentation/d/1q6alY-5pRsJ2ys_402dhEOG0pVKk1VElDbegcXFFzoA/edit?usp=drivesdk">Poster</a>
    </span>
</p>
<img src="/img/detection/pipeline.png">
<hr>

<a name="/incremental"></a>
<h2 class="pubt">Incremental Learning in Person Re-Identification</h2>
<p class="pubd">
    <span class="authors">Prajjwal Bhargava</span><br>
    <span class="conf">arXiv preprint</span>
    <span class="links">
        <a target="_blank" href="https://arxiv.org/abs/1909.13080">Paper</a>
        <a target="_blank" href="https://github.com/prajjwal1/autonomous-object-detection">Code</a>
        <a target="_blank" href="https://raw.githubusercontent.com/prajjwal1/prajjwal1.github.io/master/bibtex/gen_detection_models_iccvw19.bib">Bibtex</a>
        <a target="_blank" href="https://docs.google.com/presentation/d/1q6alY-5pRsJ2ys_402dhEOG0pVKk1VElDbegcXFFzoA/edit?usp=drivesdk">Poster</a>
    </span>
</p>
<img src="/img/incremental/our_arch.png">
<hr>

<a name="/projects"></a>

# Side projects

<div class="row">
    <div class="col-sm-12">
        <h2 class="talkt" style="font-weight:300;"><a target="_blank" href="http://github.com/prajjwal1/fluence">fluence</a></h2>
        <p class="talkd">
            Winner of Pytorch Global Hackathon 2020. A Pytorch deep learning library focussed on
            providing support for compute efficient and debiasing algorithms in transformer based
            model for NLP research. Contains implementation of Adaptive Attention, Sparsity, Layerdrop,
            Debiasing, Pruning utilities etc.
            <a target="_blank" href="http://github.com/prajjwal1/fluence"><img style="margin-top: 10px;" src="/img/projects/fluence.png"></a>
        </p>
    </div>
</div>


<div class="row">
    <div class="col-sm-12">
        <h2 class="talkt" style="font-weight:300;"><a target="_blank" href="/open-source">Open source contributions</a></h2>
        <p class="talkd">
                        Contributions to Pytorch Ecosystem
            <a target="_blank" href="/open-source"><img class="project-img" src="/img/projects/hf_pytorch.png"></a>
        </p>
    </div>
</div>


<div class="row">
    <div class="col-sm-12">
        <h2 class="talkt" style="font-weight:300;"><a target="_blank" href="https://github.com/prajjwal1/autonomous-object-detection">Autonomous Object Detection</a></h2>
        <p class="talkd">
            This project focussed on 2D object detection with Pytorch.
            User can leverage models provided from `torchvision` and use datasets provided in this project (`idd`, `cityscapes`, `bdd`)
            for training and evaluation of models. Additionally, support for incremental learning was added.
            <a target="_blank" href="https://github.com/prajjwal1/autonomous-object-detection"><img src="/img/projects/baseline_preds.png"></a>
        </p>
    </div>
</div>

<script src="/js/jquery.min.js"></script>
<script type="text/javascript">
    $('ul:gt(0) li:gt(12)').hide();
    $('#read-more-button > a').click(function() {
        $('ul:gt(0) li:gt(12)').show();
        $('#read-more-button').hide();
    });
</script>

---
