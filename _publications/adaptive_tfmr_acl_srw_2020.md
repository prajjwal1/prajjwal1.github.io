---
title: "Adaptive Transformers for Learning Multimodal Representations"
collection: publications
permalink: /publications/adaptive_tfmr_acl_srw_2020
date: 04-17-2020
venue: 'ACL SRW 2020' 
author_profile: true
<!-- citation: 'Prajjwal Bhargava <i>Association for Computational Linguistics 2020 (SRW) </i> <b>ACL SRW 2020</b>. -->'
---

### Abstract
The usage of transformers has grown from learning about language semantics to forming meaningful visiolinguistic representations. These architectures are often over-parametrized, requiring large amounts of computation. In this work, we extend adaptive approaches to learn more about model interpretability and computational efficiency. Specifically, we study attention spans, sparse, and structured dropout methods to help understand how their attention mechanism extends for vision and language tasks. We further show that these approaches can help us learn more about how the network perceives the complexity of input sequences, sparsity preferences for different modalities, and other related phenomena.

Paper: [arXiv](https://arxiv.org/abs/2005.07486)
Video: [Slideslive](http://slideslive.com/38928637)

The code can be found on [Github](https://github.com/prajjwal1/adaptive_transformers). I've also released a library related to this work [Fluence](https://github.com/prajjwal1/fluence).


